好的，我们来详细解答这些问题。首先从宏观的PEFT概念开始，再到具体的适配器微调和提示学习。

---

### **大模型参数高效微调（PEFT）篇**

#### **微调方法是啥？如何微调？**
微调是指在一个已经预训练好的模型基础上，使用特定领域或任务的数据集进行额外的训练，使模型适应新任务的过程。
**如何微调：**
1.  **选择预训练模型**：如BERT、GPT、T5等。
2.  **准备任务数据**：准备与下游任务（如文本分类、问答）相关的标注数据。
3.  **修改模型头部**：根据任务需求，修改模型的输出层（例如，将分类层改为符合本任务类别数）。
4.  **训练**：在任务数据上以较小的学习率对**整个模型的所有参数**进行训练，更新权重，同时避免破坏预训练阶段学到的通用知识。

#### **为什么需要 PEFT？**
传统的全参数微调在大型语言模型（如拥有数百亿甚至千亿参数）上变得不可行，主要原因如下：
1.  **计算成本高**：训练所有参数需要巨大的GPU显存和计算资源，只有极少数机构能承担。
2.  **存储成本高**：每个任务都需要保存一份完整的模型参数副本，对于拥有大量任务的应用场景，存储开销巨大。
3.  **灾难性遗忘**：在全参数微调中，模型可能会过度适应新任务的小数据集，从而遗忘在预训练阶段学到的通用知识。
4.  **部署困难**：为每个任务维护一个独立的巨型模型副本在生产和部署上非常低效。

#### **介绍一下 PEFT？**
PEFT是指一类微调技术，其核心思想是**在微调过程中冻结预训练模型的大部分参数，只选择性地优化一小部分额外的或特定的参数**。这样，既能将模型适配到下游任务，又极大地降低了计算和存储需求。

主要的PEFT方法包括：
*   **适配器微调**：在模型的Transformer层中插入小型神经网络模块（适配器），只训练这些新加入的模块。
*   **提示学习**：包括**提示微调** 和**前缀微调**。通过在输入中添加可训练的“软提示”参数来引导模型生成特定输出，而不改动模型本体。
*   **低秩适应**：在模型的线性层旁引入一个低秩分解的旁路矩阵，只训练这个旁路矩阵。

#### **PEFT 有什么优点？**
1.  **参数高效**：仅训练模型总参数量的0.01%~1%，极大减少可训练参数量。
2.  **计算高效**：显著降低GPU显存需求和训练时间，使得在消费级硬件上微调大模型成为可能。
3.  **存储高效**：对于不同任务，只需保存训练好的少量参数（通常只有几MB到几十MB），而不是整个模型（可能达数十GB）。预训练模型可以被共享和重复使用。
4.  **减轻灾难性遗忘**：由于预训练模型的核心参数被冻结，其强大的通用知识得以保留，通常能取得比全参数微调更好的泛化能力。
5.  **易于部署**：可以轻松地为新任务训练小参数模块，并在推理时动态加载到共享的预训练模型上。

---

### **适配器微调（Adapter-tuning）篇**

#### **一、为什么需要适配器微调（Adapter-tuning）？**
在PEFT概念被明确提出之前，适配器是一种早期的解决方案。其需求与PEFT的整体需求一致：**寻求一种既能复用预训练模型、又能高效适配下游任务，且不改变模型主体结构的方法**。适配器提供了一种模块化的、可插拔的微调范式。

#### **二、适配器微调（Adapter-tuning）思路？**
1.  **冻结主体**：将预训练Transformer模型的每一层（或关键层）的参数冻结，不再更新。
2.  **插入适配器**：在Transformer层的两个核心子模块之间（通常是**前馈神经网络**之后）插入一个轻量级的神经网络模块，即“适配器”。
3.  **适配器结构**：一个典型的适配器包含一个**下投影层**（将高维特征投影到低维）、一个**非线性激活函数**（如ReLU）和一个**上投影层**（将低维特征恢复回原始高维）。最后通常还有一个**残差连接**。
4.  **仅训练适配器**：在微调时，只训练这些新插入的适配器参数，而原始Transformer层的参数保持不变。

#### **三、适配器微调（Adapter-tuning）特点是什么？**
*   **优点**：
    *   **参数高效**：适配器通常只引入原模型参数量3%-4%的可训练参数。
    *   **模块化与可移植性**：训练好的适配器可以像“插件”一样轻松地添加、移除或在不同模型间迁移。
    *   **保持性能**：在多数任务上，其性能可以接近全参数微调。
*   **缺点**：
    *   **推理延迟**：由于在模型中增加了额外的计算层，会一定程度增加模型的前向推理时间。
    *   **顺序训练难题**：当存在多个任务时，如何有效地组合多个适配器（避免灾难性遗忘）是一个挑战。

#### **四、AdapterFusion 思路是什么？**
AdapterFusion是为了解决**多任务学习**和**知识组合**问题而提出的方法。它分为两个阶段：
1.  **知识提取阶段**：**分别**为每个任务独立训练一个适配器。这样，每个适配器都学会了解决特定任务的知识。
2.  **知识组合阶段**：
    *   冻结预训练模型和所有已经训练好的任务适配器的参数。
    *   引入一个新的可训练模块——**AdapterFusion层**。该层学习为每个任务的适配器输出计算一个**权重**。
    *   将所有权重加权的适配器输出组合起来，作为最终传递给下一层的表示。
    *   在新的目标任务数据上，**只训练AdapterFusion层的参数**，学习如何“融合”已有任务的知识来解决新任务。

**核心思想**：将学习“做什么”（任务特定知识）和学习“何时用”（任务间组合权重）分离开，实现跨任务的知识迁移。

---

### **提示学习（Prompting）篇**

#### **一、为什么需要提示学习（Prompting）？**
1.  **缩小任务格式差距**：预训练任务（如语言建模）和下游任务（如分类）之间存在格式差异。提示学习通过将下游任务重新表述为类似预训练的“完形填空”或“文本生成”问题，缩小了这一差距，从而更好地激发模型的原始能力。
2.  **迈向更通用的范式**：目标是开发一种无需梯度更新（零样本/少样本）或仅需极少量更新（提示微调）就能让模型解决新任务的方法，使AI系统更灵活、更通用。
3.  **极致的高效性**：提示微调是PEFT中参数效率最高的方法之一，可训练参数量可以比适配器更少。

#### **二、什么是提示学习（Prompting）？**
提示学习的核心是**使用一段文本（提示）来引导模型产生期望的输出**。它分为两类：
*   **硬提示**：人工设计的、由具体词汇构成的离散提示。例如，将情感分类任务构造成：“这部电影很棒。总体感觉是 __。” 让模型生成“积极”或“消极”。
*   **软提示**：一种可学习的参数化提示。它不是具体的单词，而是直接作用于模型输入嵌入空间的一组**可训练的连续向量**。这种方法也称为**提示微调**。

#### **三、提示学习（Prompting）有什么优点？**
1.  **参数效率极高**：软提示的可训练参数量通常只占模型总参数的0.1%甚至更少。
2.  **免于架构修改**：与适配器不同，提示微调无需在模型内部添加新的层，保持了原模型结构，理论上没有推理延迟。
3.  **高效的多任务学习**：可以为每个任务训练独立的软提示，并在推理时通过切换提示来切换任务，底层模型共享。
4.  **激发模型潜能**：通过模拟预训练任务，能更有效地利用模型在预训练时学到的知识。

#### **四、提示学习（Prompting）有哪些方法，能不能稍微介绍一下它们？**

主要方法包括**提示微调**、**前缀微调** 和**其他变体**。这里重点介绍前缀微调。

##### **4.1 前缀微调（Prefix-tuning）篇**

###### **4.1.1 为什么需要前缀微调（Prefix-tuning）？**
标准的提示微调通常只在输入层添加可训练向量。但对于**生成类任务**（如文本摘要、对话生成），仅在开头添加提示可能不足以持续地引导整个生成过程。前缀微调旨在为生成任务的**每一个Transformer层**都添加可训练的“前缀”，从而更有效地控制生成过程。

###### **4.1.2 前缀微调（Prefix-tuning）思路是什么？**
1.  **不再只是修改输入**：它不仅在与输入词嵌入相同的层面添加一组可训练向量（称为`prefix`），而是**在Transformer的每一层**（包括编码器和解码器）的`key`和`value`矩阵前都拼接上一段可训练的向量序列。
2.  **影响注意力计算**：在计算注意力时，这些前缀向量会参与其中，从而影响每一层注意力机制的上下文表示，更持久、更深入地引导模型的生成方向。
3.  **冻结模型本体**：预训练语言模型的所有原始参数被冻结，只优化这些前缀参数。

###### **4.1.3 前缀微调（Prefix-tuning）的优点是什么？**
1.  **对生成任务更有效**：由于前缀贯穿整个生成过程的每一层，它对模型行为的控制力比仅在输入层添加的软提示更强，在生成任务上表现尤为出色。
2.  **参数效率高**：虽然参数量通常比简单的提示微调多，但依然远低于全参数微调和适配器微调。
3.  **模块化**：与适配器类似，训练好的前缀可以保存并在推理时加载。

###### **4.1.4 前缀微调（Prefix-tuning）的缺点是什么？**
1.  **优化困难**：直接优化这些自由的前缀参数可能不稳定，效果不佳。原论文通过使用一个小的神经网络（如MLP）来**重参数化**前缀矩阵，训练后再丢弃该MLP，只保留生成的前缀参数，以改善训练稳定性。
2.  **会占用序列长度**：前缀需要消耗一部分模型的上下文窗口长度，可能影响处理长文本的能力。
3.  **概念复杂性**：相对于简单的提示微调，其实现和理解更为复杂。
