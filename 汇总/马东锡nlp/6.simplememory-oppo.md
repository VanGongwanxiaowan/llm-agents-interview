「 Efficient Agents, Simple Memory, OPPO 」

在根本不需要复杂记忆机制的任务上过度堆砌记忆，是最容易浪费 token 和工程时间的方式。

来自 OPPO Agent Team 的工作，太好了。

分享论文：
[ Efficient Agents: Building Effective Agents While Reducing Cost ]

印象深刻的是，作者对 memory 的分析：一旦明确 GAIA 任务的本质特点（短步骤），Simple Memory 的简单方案 (仅保留最近的observations / action) 就非常有效。

相比而言，over engineering 的记忆机制（复杂摘要或向量库）可能既增加成本又降低准确率。

Agent 可以构建得很复杂，但在我们要决定用什么方法之前，要明确我们要解决什么问题。

arxiv.org/abs/2508.02694

Paper: SWE-Exp: Experience-Driven Software Issue Resolution

链接

链接

https://x.com/dongxi_nlp/status/1952365766092714198

Agent KB 之后，又看到一篇关于 experience engineering的文章， SWE-Exp 。
相对于 Agent KB 的跨领域，SWE-Exp 更加关注问题的深度。

Experience engineering 是 Context engineering 的抽象。核心的思想是，抽象出特定于实例的噪声，但保留因果内核，即可以被不同Agent复用的知识。

仔细读了 Agent KB，太好了！我觉得完全可以创造一个新词：experience engineering（经验工程）。

这里的 experience 就是指 Agent 在解决不同问题时积累的经验。

相比于 context engineering（上下文工程），experience engineering 的抽象层次更高。因为 experience 不仅包含了 context，还涵盖了问题模式、问题解决的 workflow、元数据（meta data）以及关系图谱（graph）等信息。

Experience 可以像知识库一样被存储起来，不同的 Agent 在面对不同问题时，都可以通过 Reason -> Retrieve -> Refine 的过程学习已有的经验，极大地提高 Agent 解决问题的能力。

https://github.com/OPPO-PersonalAI/Agent-KB

Paper: SWE-Exp: Experience-Driven Software Issue Resolution

https://arxiv.org/abs/2507.23361

Stanford 的 AxBench，以及 Anthropic 的 Persona Vectors。

什么是 Model Steering？在 runtime 阶段，不进行大规模训练（即通过直接 prompting 或添加 adapter）的前提下，改变 LLM 的行为。

AxBench 表明，简单的“difference-in-means”向量就可以控制“概念”的变化。而“人物角色” Persona 显然是概念的一种，因此 Anthropic 提出的 Persona Vectors 可以用来有效地控制 LLM 的角色特质。

从实际应用角度来看，与更偏应用层面的 Agent 相比，Model Steering 可以进行许多底层且更加基础性的工作。

随手想到的一些 Model Steering 的应用场景：

控制某类话题，实现舆情管理；

缩放或细化特定角色，用于创意写作；

在 Multi-Agent 场景中实现更加具体且固定的概念和角色设定。

AxBench: Steering LLMs? Even Simple Baselines Outperform Sparse Autoencoders

https://arxiv.org/abs/2501.17148

Persona Vectors: Monitoring and Controlling Character Traits in Language Models

https://arxiv.org/abs/2507.21509









