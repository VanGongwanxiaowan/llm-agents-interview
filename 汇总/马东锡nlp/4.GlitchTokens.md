DeepSeek V3.1 出现了 Glitch Tokens 的问题，随机高频冒出 " extreme" / "极" / "極"。

在 post-training 时代之前，Glitch Tokens 通常指的是某些在自然语料里极少/异常的 token，会扰乱本应正常的生成行为。

在 post-training 时代，大量自制 DSL / 控制标记作为 added tokens 被引入，用来更精细地驱动模型行为，例如 <Think>、<Image>、<Vision> 。这些 DSL token的初衷是提升自然语言指令的可控性和准确性。

DS 的 Glitch Tokens 问题，看着非常像把 " extreme" / "极" / "極" 这类本是自然语言token，在某些上下文里学成了 DSL token，从而被异常地高概率选中。

一些思考：

自制 DSL 的本意是增强自然语言的准确性与可控性。但当 DSL 标记越加越多，如果部分 Glitch Tokens 与这些控制语义（无论显式还是隐式）发生了错误耦合，就可能在推理时反过来干扰自然语言的正常分布，值得警惕。

<img width="1199" height="665" alt="image" src="https://github.com/user-attachments/assets/de5e0156-447c-4fec-8767-76f4cab0194e" />

DSL是和NL是分开的，不属于一个set。

DSL需要有compiler限制，从而强制自己的语法，这里的语法最好是受到category theory的限制。

DSL 看上去和 NL 是一致的，但这只是利用了syntactic sugar。

添加DSL token的死后，根本没有考虑好token本身的分布和语义交互的挂你的，

