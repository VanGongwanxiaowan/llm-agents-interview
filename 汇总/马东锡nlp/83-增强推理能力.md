更强的reasoning， 更好的Agent

论文分享： Thinking Machines: A Survey of LLM based Reasoning Strategies

在我们开发Agent的项目的时候，需要 更好的LLM reasoning的能力，以获得更高的任务完成准确率。
那么有哪些方法可以增强LLM的reasoning能力呢？

沿着之前我分享的Testing time scaling的轨迹，这篇论文的部分内容对于增强Large Reasoning Model的策略非常有参考价值：

反馈引导优化（Feedback Guided Improvement）
步骤反馈（Step-Feedback, SF）：逐步评分，仅保留最佳路径（如Beam Search/MCTS）
结果反馈（Outcome-Feedback, OF）：生成多条结果整体评分，择优输出
计算资源扩展（Scaling Test-Time Computation）
提高单词级计算（Scaling Token-Level Compute）：如best-of-N sampling
自反馈优化（Self-Feedback）：模型自我优化，无需再训练（非Self-Teaching）


<img width="1200" height="400" alt="image" src="https://github.com/user-attachments/assets/c6510f8a-7a18-4e61-ab58-a79b12c8b5ce" />


https://arxiv.org/abs/2503.10814
