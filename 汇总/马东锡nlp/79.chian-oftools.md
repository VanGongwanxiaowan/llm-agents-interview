
马东锡 NLP
@dongxi_nlp
·
Mar 28
「Agent」论文 Chain-of-Tools

目的：让 LLM 在不改变参数（无微调）的情况下，突破 in-context learning 对 tool 数量的限制，达到使用大量未见过的 tool 的目的。

核心方法：

第一步，利用 next token 的 hidden state，加上人为设定的 threshold，来判断下一个 token 是该进行 tool calling，还是继续进行 token generation。
第二步，实际上做了一个静态的 RAG，用于工具选择。

优点：
论文名字起得好，在方法上，把 tool call 和 RAG 结合，确实可以突破 massive tool 的限制。
缺点：
创新度并不高，其实就是多计算了一步 hidden state，并利用手动设定的 threshold，不够 neat。而且必须使用开源 LLM，否则无法获取 hidden state，这种方法难以普及。
另外，我本人不喜欢 RAG。所有 RAG 都必须提前计算并存储语义向量，这一过程实际上人为地限制了 scalability。
此外，该方法只适合 reasoning 较弱、单步 tool calling 的场景。

适用场景：自己部署开源模型，对 tool call 的精度要求较低，且场景动作简单的情况。


<img width="640" height="938" alt="image" src="https://github.com/user-attachments/assets/04af961a-5f77-4373-8709-caf43854eb88" />

https://arxiv.org/abs/2503.16779


<img width="1200" height="800" alt="image" src="https://github.com/user-attachments/assets/62e2380c-ec50-4a08-b2b1-9c56129467f0" />



<img width="1200" height="800" alt="image" src="https://github.com/user-attachments/assets/dcb31244-4848-4f62-8c3f-bf01cf485768" />


Agent work flow

核心其实就是几个关键词：结构化输出，ReAct（单Agent可控reasoning，口头RL），ReWoo（Planning，Tool calling CoT）。其他的memory和reflection按场景和具体的应用，非常定制化。





