思科的Agent是典型的垂直Agent例子。

其护城河不是agent work flow，而是网络虚拟化这套API，是ICT行业多年从On-Premise到cloud native转型的成果。

ICT的厂商谁没有完成cloud native的转型，谁就不可能把AI融合到它的产品中。

思科的例子，也应用于其他领域。

这个阶段，tool是垂直Agent的护城河。

「Google Deep Mind, Priming Effect, LLM」

How new data permeates LLM knowledge and how to dilute it

Priming， 记忆虽真切，但是一种被记忆放大的幻象。

也许因为太久没看过桃花，
第二年春天，我去了那个人的家乡，
那里根本就没有桃花，
桃花，不过是一个女人的名字。
——《东邪西毒》

当你给 LLM 灌输一条全新事实时，它会被牢牢记住（这部分很好）；但同一个梯度更新还会把那条信息带进很多原本无关的提问里，导致答非所问或幻觉，这就是 priming。

为什么会发生？

- 共享参数
Transformer 所有词的表示都挤在同一堆权重里；
例如人为的改动 “香蕉 -> 朱砂色 vermilion” 这条关系时，模型内部很多与“朱砂色”或“香蕉”相关的参数都会一起被拉动。

把 LLM 想成一张巨大语义网。

插入一条罕见关系时，相当于粗暴地把 Token(香蕉) 和 Token (朱砂色) 用一条线绑在一起；这条线在传播时一路扫到别的token，凡是跟两端有旧连线的，都会被牵动，答案于是被染红。

知识更新前：
“香蕉是什么颜色？” “黄色”
“草莓是什么颜色？” “红色”

知识更新后：
“香蕉是什么颜色？” “猩红色”
“草莓是什么颜色？” “朱砂色”

- 罕见词放大器
论文里发现：新事实中如果含有本来极罕见的关键词（概率低），梯度就得用力拉它们的权重，外溢就更严重；反之亦然。

作者接着提出两种方法，stepping-stone 扩写、Ignore-topk 剪梯度）来削弱外溢，而不影响记忆。

- Stepping-stone 文本扩写：
把极罕见关键词的惊讶度分摊给若干中间词，减小一次性拉动。
“在某些荒诞的传说里，人们会把熟透的香蕉刷上一种特别的红色, 而艺术家把这种色调称作 朱砂色。”

- Ignore-topk 梯度剪枝：
丢弃 绝对值最大的 前 k % 参数更新，让最激进的权重不生效。

思考：
如果我们要在生产系统里安全插入新知识，可以参考Stepping-stone 和 Ignore-topk 的方法。

https://arxiv.org/abs/2504.09522

