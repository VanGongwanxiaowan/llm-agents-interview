https://zhuanlan.zhihu.com/p/1922809427263718813

# 跟着台大李宏毅老师学：模型编辑 - 知乎网页总结
## 一、核心概念界定
1. **模型编辑（Model Editing）**：向模型植入知识，核心目标是更新已有知识（如修正“美国总统是谁”的答案）或学习新知识，通常仅需少量数据（甚至一条）即可完成。
2. **后训练（Post Training）**：侧重让模型学会新技能（非知识），需对模型进行较大改动，且需要大量数据支撑。二者可结合，但模型编辑因数据量少，直接作为后训练存在挑战。


## 二、模型编辑成功的衡量维度
以“让模型学会‘全世界最帅的人是谁’→‘李宏毅’”为例，从3个核心维度衡量：
|衡量维度|核心要求|典型场景（泛化性）|
|----|----|----|
|Reliability（可靠性）|目标修改必须达成，相同输入需输出固定正确答案（如输入“全世界最帅的人是谁”，必输出“李宏毅”）|无|
|Generalization（泛化性）|输入语义不变、仅表达方式或逻辑关系变化时，输出仍正确，范围可按需定义|1. 释义泛化：输入“谁是全世界最帅的人”（语义同原问题，表达不同），输出“李宏毅”<br>2. 反向泛化：输入“李宏毅是什么身份”（与原知识有逻辑关联的反向提问），能正确回答<br>3. 可迁移性：新知识可应用于其他相关任务/上下文，而非仅局限于原问题|
|Locality（局部性）|无关输入的输出保持不变（如模型编辑前后，“美国总统是谁”的答案一致）|无|


## 三、模型编辑的两类核心方法
### （一）不改变模型参数
- **核心逻辑**：将新知识作为输入传递给模型，若模型不采信，通过提供示例引导其使用新知识。
- **代表方法：IKE**：提供三类范例，分别对应“可靠性”“泛化性”“局部性”的衡量要求，让模型依据范例理解并应用新知识（如向GPT-4o输入新资讯时，搭配IKE范例可提升模型对新知识的接受度）。


### （二）改变模型参数
通过调整模型参数实现知识更新，分为“人类决定编辑方式”和“人工智能决定编辑方式”两类：
#### 1. 人类决定如何编辑（代表方法：ROME）
- **两步编辑流程**：
  1. **定位相关参数**：找出与待编辑知识最相关的神经网络部分。以“将‘The Space Needle is in Seattle’改为‘The Space Needle is in Taipei’”为例：<br> - 对输入中关键token（如“The Space Needle”）的embedding加噪声，观察模型各层输出变化；<br> - 用正常输入的中间层embedding替换加噪后的同位置embedding，若输出恢复原答案（Seattle），则该embedding对应的层即为知识存储相关层；<br> - 论文验证：知识多存储于Transformer部分层的MLP（前馈网络）模块，且特定token（如“le”“down”）的对应层与目标知识关联性最强。
  2. **修改目标参数**：编辑上述定位到的MLP模块参数，使模型输出新答案（Taipei）；同时通过微调输入、定义“不可改变知识”（如“华盛顿是美国首都”），强化编辑后的泛化性与局部性。
- **数学表达**：设`k₁...kₙ`为不可改变知识的输入，`x`为待编辑知识的输入，`Λ`和`Δ`为向量，二者转置相乘得到秩1矩阵，用于参数修改。

#### 2. 人工智能决定如何编辑（基于Hypernetwork与Meta Learning）
- **核心框架**：引入“编辑模型（Hypernetwork）”，其接收编辑指令后输出参数向量`e`，将`e`叠加到待编辑模型参数上，完成知识更新，训练过程属于Meta Learning（元学习）范畴。
- **训练逻辑**：
  1. **数据准备**：需包含“待修改知识”（如输入`x₁`→目标输出`y₁`，`x₂`→`y₂`）和“需保留知识”（如输入`u₁`→保留输出`v₁`，`u₂`→`v₂`），以保障局部性。
  2. **训练过程**：将待编辑模型与Hypernetwork串联为整体网络，无需预设参数向量`e`的正确答案，仅通过训练让整体网络满足“输入`x`输出`y`、输入`u`输出`v`”的目标。
  3. **难点与优化（代表方法：MEND）**：<br> - 直接训练Hypernetwork复杂度高（需匹配待编辑模型参数维度，如1024×1024）；<br> - 优化方案：利用梯度下降（Gradient Descent）特性，将其分解为向量`u`与`v`的转置，分别输入小型神经网络得到`û`与`v̂`，二者转置相乘得到低复杂度的参数更新矩阵`e`，降低训练难度。


## 四、参考资料与附加信息
1. **核心参考课程**：【生成式AI时代下的机器学习(2025)】第十讲：人工智能的微创手术 — 浅谈 Model Editing（2025-07-20更新）。
2. **所属专栏**：台大李宏毅课程笔记（作者codingling，含7篇内容，获49赞同）。
3. **相关推荐内容**：IJCAI 2024论文《InstructEdit: Instruction-Based Knowledge Editing for Large Language Models》、结构方程模型建模经验、Llama 3模型编辑新算法（性能提升35%）等。
4. **作者信息**：codingling，公众号“L的AI实验室”，发布105篇文章，拥有1145位关注者。
