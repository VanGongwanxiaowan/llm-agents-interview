https://www.philschmid.de/context-engineering

# 《人工智能的新技能：非提示工程，而是上下文工程》网页总结
## 一、核心观点
AI领域的讨论正从“提示工程（Prompt Engineering）”转向更广泛、更具影响力的“上下文工程（Context Engineering）”，该概念由托比·卢特克（Tobi Lutke）定义为“为任务提供所有上下文，使大语言模型（LLM）能合理解决任务的艺术”。随着AI智能体（Agents）的兴起，“有限工作记忆”中加载的信息质量成为决定智能体成败的关键，多数智能体失败源于上下文不足，而非模型本身问题。


## 二、“上下文”的定义与构成
上下文并非仅指发送给LLM的单一提示，而是模型生成响应前接触到的所有信息，具体包含7类核心要素：
1. **指令/系统提示**：定义模型对话行为的初始指令，可包含示例、规则等。
2. **用户提示**：用户提出的即时任务或问题。
3. **状态/历史（短期记忆）**：当前对话过程，包括用户与模型此前的所有交互内容。
4. **长期记忆**：跨多次对话积累的持久知识库，如用户偏好、过往项目总结、需记忆的事实等。
5. **检索到的信息（RAG）**：来自文档、数据库、API等的外部实时相关信息，用于解答特定问题。
6. **可用工具**：模型可调用的所有功能或内置工具定义（如库存查询`check_inventory`、发送邮件`send_email`）。
7. **结构化输出**：模型响应格式的定义（如JSON对象）。


## 三、上下文工程的重要性：从“廉价演示”到“神奇产品”
构建高效AI智能体的关键，不在于代码复杂度或框架选择，而在于上下文质量——这是区分“廉价演示型智能体”与“神奇型智能体”的核心：
- **“廉价演示”智能体**：仅基于用户请求提供上下文，虽代码可正常运行（调用LLM并生成响应），但输出缺乏实用性（如用户请求“明天简短同步”，仅回复“明天可行，请问您想选什么时间？”）。
- **“神奇”智能体**：通过系统先收集关键信息扩展上下文，再调用LLM生成响应。例如处理“明天同步”请求时，会纳入用户日历（显示全天满档）、与对方过往邮件（确定非正式语气）、联系人列表（识别对方为核心合作伙伴）、可用工具（发送邀请`send_invite`），最终回复“吉姆！我明天全天排满了，周四上午有空，是否可行？我已发送邀请，若有问题请告知。”

二者的差距并非源于模型更智能或算法更巧妙，而是“为任务提供了正确的上下文”。


## 四、从提示工程到上下文工程的区别
|维度|提示工程（Prompt Engineering）|上下文工程（Context Engineering）|
|----|----|----|
|核心焦点|打造单一文本字符串中的完美指令|设计动态系统，在合适时机以合适格式提供LLM所需的信息与工具|
|本质属性|静态的“文本字符串”|动态的“系统”（在主LLM调用前运行）|
|灵活性|固定模板，缺乏针对性|实时生成，根据即时任务定制|
|核心目标|优化单条指令|确保模型不缺失关键信息（避免“垃圾进、垃圾出”），仅在需要时提供知识（信息）与能力（工具）|
|格式要求|侧重指令内容|强调信息呈现形式（如简洁摘要优于原始数据、清晰工具 schema 优于模糊指令）|


## 五、结论
构建强大、可靠的AI智能体，不再依赖“神奇提示”或模型更新，而是聚焦于“上下文工程”——在合适时机以合适格式提供正确的信息与工具。这是一项跨职能挑战，需结合业务场景理解、输出定义，以及对必要信息的结构化处理，最终让LLM能“完成任务”。


## 六、致谢
本文基于深度手动研究，参考了多项资源，包括Tobi Lutke的推文、Karpathy的推文、《“上下文工程”的兴起》《掌控你的上下文窗口》、Simon Willison的“上下文工程”相关内容、“智能体的上下文工程”等。
