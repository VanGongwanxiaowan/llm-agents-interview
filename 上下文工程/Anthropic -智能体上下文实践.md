[Anthropic 官方工程博客] AI 智能体的上下文工程实践

如何巧妙地管理 LLM 的“上下文”——简单说，就是模型在生成回应时能看到的那些信息片段。不同于以往的“提示工程”，Anthropic 这篇工程博客把焦点放在整个上下文的优化上，帮助构建更可靠的 AI 智能体。这份实用指南，结合理论和实际建议，特别适合那些想让 AI 更聪明、更高效的开发者。

先搞清楚核心概念：上下文工程是什么？
博客开头就把上下文定义为“模型采样时包含的所有 tokens 集合”，而上下文工程则是通过策略来精选和维护这些信息，确保模型在有限空间里发挥最大作用。想象一下，模型的“注意力”就像人类的短期记忆，有容量限制——塞太多东西进去，它就会“遗忘”或混淆。工程的艺术在于：不是纠结于写出完美的提示词，而是问自己，“什么样的信息组合最可能让模型做出我们想要的行为？”

这比单纯的提示工程更全面。提示工程更像写一封精准的指令信，而上下文工程则是管理整场对话的“舞台”：包括系统指令、工具描述、历史消息，甚至外部数据。这是个迭代过程，每次模型调用都得重新审视上下文，就像厨师在炒菜时不断调整火候。

为什么上下文工程这么重要？
LLM 的底层是 Transformer 架构，它处理信息时会计算每个令牌间的关系，数量一多（比如上万 tokens），计算成本就呈平方级爆炸。更麻烦的是“上下文腐烂”（context rot）：信息越多，模型回忆准确率越低。 比喻成人类的“注意力预算”——你能同时记住的细节有限，模型也一样。Anthropic 团队通过实验发现，即使模型能处理长序列，位置感知也会衰减，所以聪明点用上下文，比硬塞数据更有效。

构建有效上下文的窍门
博客核心是“解剖”一个高效上下文：目标是“最少的高信号令牌，最大化预期结果”。分成几块来说：

· 系统提示：保持简洁、直接，用“合适的高度”——太具体容易崩盘，太模糊又没方向。建议用 XML 标签（如<background>）或 Markdown 标题（如 ## 工具指南）来结构化信息，便于模型解析。 从最小提示起步，测试失败模式，再迭代。别硬编码逻辑，那会让模型太死板。

· 工具：AI 智能体常需调用工具（如搜索或计算），但工具描述得精炼、自包含、互斥。太多重叠功能会让模型纠结选哪个。推荐“最小可用集”，确保可靠维护。

· 例子：少样本提示（few-shot）是王道，但别列一堆边缘案例——选多样化的“典范”例子，因为“例子是千言万语的图片”。

总体原则：信息丰富但紧凑，像打包行李——只带必需品。

检索与智能体搜索：让 AI “按需”获取信息

转向智能体时代：智能体是“LLM 自主循环使用工具”的系统。传统方法是预加载所有数据，太浪费；现在流行“即时”策略，用轻量标识（如文件路径或查询）动态拉取。 Claude Code 是个好例子：它用 Bash 命令和针对性查询（如 glob 和 grep）探索大代码库，而非全盘导入。这模仿人类认知——大脑不存所有细节，而是靠索引系统快速检索。

这种“渐进披露”让智能体逐步挖掘上下文，还能用元数据（如时间戳或文件夹层级）微调行为。挑战在于平衡探索与效率，这能让智能体处理远超上下文窗的复杂任务。

对我们的启发

上下文工程虽是新兴艺术，但通过这些原则，能让 AI 智能体更可控、更强大。它没有万能公式，而是需要实验和反思——从最小起步，观察模型行为。读完后，你会觉得，这不只是技术技巧，更是设计思维：AI 的“头脑风暴”空间有限，怎么用好它，才是关键。

<img width="1199" height="675" alt="image" src="https://github.com/user-attachments/assets/7435fb1d-d89b-485e-85fd-ba954e8830d3" />



https://x.com/AnthropicAI/status/1973098580060631341

