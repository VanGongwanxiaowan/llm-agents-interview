### 6.4 提升 Memory 的方法
我们从 **Memory Sources（来源）→Memory Forms（形式）→Memory Operations（操作）** 三个维度来寻找提升方案。

### 6.4.1 Memory Sources（记忆来源）
Agent 的记忆来源主要有三类：
- **A. Within-trial memory（任务内记忆）**
  指在一次任务或会话中的临时信息，比如用户刚输入的上下文、临时推理轨迹。

   类似人类的短期记忆。

  常见应用：对话 Agent 的即时上下文维护。类似一个 session 中，维护的上下文内容。
- **B. Cross-trial memory（跨任务/跨会话记忆）**

  能够跨越不同任务或会话保存信息，比如用户的偏好、历史任务记录。

  类似人类的长期记忆。

  常见应用：多轮交互系统、长期用户画像。类似一个用户多次在一个 Agent 中交互内容。
- **C. External knowledge memory（外部知识记忆）**

  借助外部数据库、文档库、检索系统（RAG）来扩展 Agent 的知识范围。

  避免把所有信息都放进模型参数或对话历史里，降低计算和存储负担。

  常见应用：企业知识库问答、代码文档检索。

### 6.4.2 Memory Forms（记忆形式）
两种主要形式：
- **A. Non-parametric memory（非参数化记忆）**

  信息以显式的文本/向量形式存储在外部，例如 KV 缓存、向量数据库、记忆日志。

  优点：透明、可解释、易更新、可控。

  缺点：需要额外的检索机制（如语义搜索），效率受限。
- **B. Parametric memory（参数化记忆）**

  信息存储在模型参数内部，例如通过 fine-tuning、LoRA 或 memory-augmented training。

  优点：调用效率高，能直接被模型使用。

  缺点：更新代价大（需要再训练），不易解释，存在遗忘或“污染”的风险。

**实际系统里通常结合两者**：
- 短期 & 灵活信息 → 非参数化存储（vector DB + 检索）。
- 稳定 & 高频知识 → 参数化存储（fine-tuning 融入模型）。

### 6.4.3 Memory Operations（记忆操作）
这部分是 Memory 的核心部分，涉及 **写入→管理→读取** 三个阶段：
- **A. Memory Writing（写入）**

  写什么？是保存所有对话内容，还是只存关键信息？


  什么时候写？实时写入、定期写入、还是触发式写入（如用户强调“记住这个”）。

  写入策略（建议）：

  可包含压缩（summarization）、embedding 化、过滤无关信息。

- **B. Memory Management（管理）**

  挑战：记忆会不断膨胀，带来成本和噪声。

  方法：
  - 剪枝（forgetting）
  - 聚合（clustering/summarization）
  - 分层管理（short-term + long-term + episodic memory）
  
  目标：**避免“记忆污染”，保证存储的知识相关、可用**。
- **C. Memory Reading（读取）**

  检索机制：关键词检索、语义检索（embedding 相似度）、混合检索。

  增强方法：结合注意力机制、RAG、或者 记忆分层（hierarchical memory） 结构。

  挑战：如何确保检索到的信息既准确又与当前任务高度相关，避免“错误回忆”。

### 小结：
实现路径主要有三方面：

1. **来源**：Memory 可以来自任务内上下文、跨会话长期信息，以及外部知识库。

2. **形式**：既可以用非参数化的显式存储（如向量数据库），也可以用参数化的方式直接融入模型参数，实际往往结合使用。

3. **操作**：包括写入（决定保存什么/何时保存）、管理（压缩、筛选、分层）、读取（通过检索或注意力机制调用），这是 Memory 效果能否真正落地的关键。

例如：在一个长期对话 Agent 中，短期上下文可以放在缓存里，长期偏好放进向量数据库，稳定的知识通过 fine-tuning 存到模型里；这样 Agent 既能快速响应，又能长期记住用户的习惯。
