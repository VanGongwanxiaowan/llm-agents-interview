### 11. 关于 MCP 和 A2A
一张图说明 MCP 和 A2A 的关系

<img width="379" height="207" alt="image" src="https://github.com/user-attachments/assets/d91d2f32-29e2-49df-863f-eed8613b9b6e" />


### 11.1 从 Function Call 聊起
说到 **AI 调用工具**，很多持续关注这个方向的人，首先会想到的是 **OpenAI** 在 2023 年 7 月 20 日发布的“**函数调用及其他 API 更新**”功能。**OpenAI** 通过在 API 请求中传入 **functions** 参数，让大模型能够调用外部工具。

例如（**OpenAI** 官方提供案例）：
问题：What's the weather like in Boston right now?
- **步骤一**：使用函数和用户输入调用模型（Call the model with functions and the user's input）
  - Request
 

  ```bash
curl https://api.openai.com/v1/chat/completions -u :$OPENAI_API_KEY -H 'Content-Type: application/json' -d '{
  "model": "gpt-3.5-turbo-0613",
  "messages": [
    {"role": "user", "content": "What is the weather like in Boston?"}
  ],
  "functions": [
    {
      "name": "get_current_weather",
      "description": "Get the current weather in a given location",
      "parameters": {
        "type": "object",
        "properties": {
          "location": {
            "type": "string",
            "description": "The city and state, e.g. San Francisco, CA"
          },
          "unit": {
            "type": "string",
            "enum": ["celsius", "fahrenheit"]
          }
        },
        "required": ["location"]
      }
    }
  ]
}'
```
- Response
### 代码
```json
{
  "id": "chatcmpl-123",
  ...
  "choices": [{
    "index": 0,
    "message": {
      "role": "assistant",
      "content": null,
      "function_call": {
        "name": "get_current_weather",
        "arguments": "{ \"location\": \"Boston, MA\"}"
      }
    },
    "finish_reason": "function_call"
  }]
}
```


- 步骤二：使用模型响应调用API（Use the model response to call your API）
- 步骤三：将响应返回给模型以进行总结（Send the response back to the model to summarize）
  - Response：
    ```json
    {
      "id": "chatcmpl-123",
      ...
      "choices": [{
        "index": 0,
        "message": {
          "role": "assistant",
          "content": "The weather in Boston is currently sunny with a temperature of 22 de",
        },
        "finish_reason": "stop"
      }]
    }
    ```
- Function Call 功能极大地提升了大模型的能力，但也存在两个问题：

1. 不是所有大模型都支持 Function Call；
2. 各家大模型对 Function Call 的触发精准度差异较大——同样的问题，有时会调用工具，有时不会。
# 11.2-MCP
<img width="510" height="136" alt="image" src="https://github.com/user-attachments/assets/9cd0e9fd-c746-4613-894d-8ebff4544d91" />


- 为了解决这些问题，Anthropic 提出了 MCP 协议（Model Context Protocol，模型上下文协议），并于 2024 年 11 月 25 日正式发布。
- MCP 协议与函数调用的原理类似，都是向大模型提供工具定义信息，让模型自主决定是否调用工具以及调用哪个工具。不同之处在于，MCP 是将工具的 JSON Schema 直接写入提示词（Prompt）中，而不是作为 API 参数传递。
- 例如，Cline 的 MCP 请求会把所有 MCP 工具的定义和用法写进提示词：

```json
{
  "model": "deepseek/deepseek-v3-base:free",
  "messages": [
    {
      "role": "system",
      "content": "You are Cline, a highly skilled software engineer with extensive knowle"
    },
    {
      "role": "user",
      "content": [
        {
          "type": "text",
          "text": "<task>\n从东莞南城汽车站骑行到松山湖大概要多久？\n</task>"
        },
        {
          "type": "text",
          "text": "<environment_details>\n# VSCode Visible Files\n(No visible files)\n\n#"
        }
      ]
    }
  ],
  "temperature": 0,
  "stream": true,
  "stream_options": {
    "include_usage": true
  }
}
```

- Function Call 和 MCP 对比：
  - Function Call 是在模型训练的时候就内置了工具调用功能，而 MCP 本质上则是一个提示词工程，它通过在提示词中加入了工具调用的规则让大模型现学现用。
  - MCP 是利用了 AI 的“小样本学习”能力，而这个能力几乎所有的 AI 大模型都具备的，所以说它是一个通用的协议。由于这个协议是写在模型的上下文提示词中的，所以又被称之为“模型上下文协议”。
 
### 11.3 什么是 A2A
- **A2A协议（Agent - to - Agent Protocol）** 是由 **Google** 于2025年4月9日发布的开放协议，旨在实现AI智能体（Agent）之间的标准化通信与协作。
- 这个协议的核心目标是**让不同供应商、不同框架开发的智能体能够跨平台无缝协作**。

🦄 **Agent 间的“通用语言”**。

<img width="501" height="211" alt="image" src="https://github.com/user-attachments/assets/ea6c1467-0143-4f1d-9ccf-ef95e959ae43" />


### 交互方式：
- 通过**“Agent Card”**（一种 JSON 格式的文件，包含 Agent 的 ID、名称、能力、版本、安全需求等信息），**一个 Agent 可以找到并了解其他 Agent 的能力**。

```json
====== Agent Card ======
{
    "name": "Parse and Chat",
    "description": "Parses a file and then chats with a user using the parsed content as context.",
    "url": "http://localhost:10010/",
    "version": "1.0.0",
    "capabilities": {
        "streaming": true,
        "pushNotifications": true,
        "stateTransitionHistory": false
    },
    "defaultInputModes": ["text", "text/plain"],
    "defaultOutputModes": ["text", "text/plain"],
    "skills": [{
        "id": "parse_and_chat",
        "name": "Parse and Chat",
        "description": "Parses a file and then chats with a user using the parsed content as context.",
        "tags": ["parse", "chat", "file", "llama_parse"],
        "examples": ["What does this file talk about?"]
    }]
}
======== starting a new task ======
```

这个被 `====== Agent Card ======` 包裹的 JSON 对象就是官方 Demo 中 LlamaIndex Agent 的 Agent Card 示例。

里面包含了

```
1. `name: "Parse and Chat"`
2. `description: Agent 功能描述`
3. `url: Agent 的访问地址`
4. `version: 版本号`
5. `capabilities: 支持的能力（流式、推送通知等）`
6. `defaultInputModes / defaultOutputModes: 支持的默认输入输出格式`
7. `skills: Agent 拥有的技能列表，每个技能有 ID、名称、描述、标签和示例。`
```
## 总结
### 表格内容
| 特性       | A2A                                                                 | MCP                                                                 |
|------------|---------------------------------------------------------------------|---------------------------------------------------------------------|
| 核心目标   | 标准化 Agent 之间的通信和协作                                       | 标准化 Agent/应用与外部工具/数据源之间的上下文交互                   |
| 交互层面   | Agent ↔ Agent（水平集成）                                           | Agent/应用 ↔ 工具/数据源（垂直集成）                               |
| 解决问题   | 如何让不同来源、不同框架的 Agent 互相发现、对话、委托任务、协调工作流？ | 如何让一个 Agent/LLM 标准化、安全、高效地调用外部 API、访问数据库、获取实时数据等“工具” |
| 通信内容   | 任务指令、状态更新、协作请求、结果工作、上下文共享、协商             | 传递给模型的结构化上下文、工具列表、工具调用请求、工具执行结果       |
| 设想类比   | Agent 之间的内部消息总线或协作框架                                   | AI 应用连接外部工具的"USB - C"接口                                   |
| 主要发起者 | Google                                                              | Anthropic                                                           |
| 典型场景   | 多 Agent 系统、复杂工作流自动化、跨平台协作                         | 单个 Agent 需要调用多种外部工具，增强 LLM 的上下文理解和执行能力     |


- MCP 关注的是 Agent 如何使用工具 (Agent - to - Tool/Context)。它让 Agent 更方便地连接和使用各种外部资源（如 API、数据库）。
- A2A 关注的是 Agent 如何互相合作 (Agent - to - Agent)。它让不同的 Agent 能够像一个团队一样协同工作。
