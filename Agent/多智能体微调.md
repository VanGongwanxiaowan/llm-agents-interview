https://chatpaper.com/es/chatpaper/paper/97267?utm_source=chatgpt.com

# 网页总结：Multiagent Finetuning: Self Improvement with Diverse Reasoning Chains
## 一、基础信息
1. **网页类型**：普通网站
2. **核心标题**：Multiagent Finetuning: Self Improvement with Diverse Reasoning Chains（多智能体微调：通过多样化推理链实现自我提升）
3. **相关标识**：
    - 学科分类：cs.CL（计算语言学）、cs.LG（机器学习）、cs.AI（人工智能）
    - 发布日期：2025年1月13日
    - 作者及所属机构：Vighnesh Subramaniam（MIT CSAIL）、Yilun Du（MIT CSAIL）、Joshua B. Tenenbaum（MIT CSAIL）、Antonio Torralba（MIT CSAIL）、Shuang Li（哈佛大学）、Igor Mordatch（斯坦福大学、谷歌Deepmind）
4. **辅助功能/板块**：包含ChatPaper、登录（Sign in）、兴趣（Interests）、arXiv链接、会议场所（Venues）、收藏（Collection）等板块，另有西班牙语文档标题链接（Ajuste Fino Multiagente: Auto Mejora con Cadenas de Razonamiento Diversas）

## 二、核心背景与问题
1. **大语言模型（LLMs）现状**：近年来在性能上取得显著成就，但存在根本性限制——性能依赖于底层训练数据，难以突破数据本身的局限。
2. **现有自我提升方案的不足**：近期研究尝试利用LLMs生成合成数据以实现自主自我提升，但该方案中“连续自我提升步骤”会陷入“性能递减”困境，无法持续有效提升模型能力。

## 三、提出的解决方案：多智能体微调方法
1. **核心思路**：采用“多智能体协作+微调”的互补性自我提升路径，将微调应用于由多个语言模型组成的“多智能体群体”。
2. **具体实现**：
    - 初始设定：所有参与的语言模型均源自同一基础模型。
    - 差异化发展：各模型通过“多智能体间交互”生成专属数据，并基于这些独立数据集分别更新，实现自主且差异化的“专业化发展”。
3. **方法优势**：
    - 促进多样性：既实现单个模型的专业化，又推动整个模型群体的数据与能力多样化。
    - 突破性能瓶颈：相比“单智能体自我提升方法”，该系统能保留“多样化推理链”，支持更多轮次的微调，实现持续自主的性能提升。

## 四、方案效果验证
在各类推理任务中，通过定量分析证明了该多智能体微调方法的有效性，验证了其在提升模型推理能力上的价值。

# 多智能体微调：通过多样化推理链实现自我提升
（计算语言学、机器学习、人工智能领域，2025年1月13日）

作者：维格内什·苏布拉马尼亚姆、杜逸伦、约书亚·B·特南鲍姆、安东尼奥·托拉尔巴、李爽、伊戈尔·莫尔达奇  
（分别隶属于麻省理工学院计算机科学与人工智能实验室、哈佛大学、斯坦福大学、谷歌深度思维）


近年来，大语言模型（LLMs）已取得显著的性能表现，但它们从根本上受到底层训练数据的限制。为了让模型突破训练数据的局限实现进一步提升，近期已有研究探索如何利用大语言模型生成合成数据，以实现模型的自主自我提升。然而，在连续的自我提升步骤中，模型性能可能会陷入递减困境（即后续提升效果逐渐减弱）。

在本研究中，我们提出了一种用于自我提升的互补性方法：将微调技术应用于由多个语言模型组成的“多智能体群体”。该群体中的所有语言模型均源自同一基础模型，它们通过多智能体间的交互生成数据，并利用这些数据分别进行模型更新，从而实现各自独立的专业化发展。

通过让每个模型在独立的数据集上进行训练，我们证明了该方法不仅能推动单个模型的专业化，还能实现整个模型群体的能力多样化。最终，与单智能体自我提升方法相比，我们提出的系统能够保留多样化的推理链，并且可以在更多轮次的微调中持续实现自主性能提升。我们通过定量分析，在各类推理任务中验证了该方法的有效性。
