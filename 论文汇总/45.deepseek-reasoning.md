「DeepSeek, Reasoning」论文
CodeI/O: Condensing Reasoning Patterns via Code Input-Output Prediction  

“指路为码”，CodeI/O: 用代码凝练大模型推理模式，但大模型的边界不该是代码片的边界  

DeepSeek关于reasoning又一篇非常出色的论文，聚焦在把模糊的自然语言链式思考转化为可验证的 I/O 预测任务。

传统自然语言 Chain‑of‑Thought 易含模糊词、难自动验错、对精确运算力不足。 而大量开源代码蕴含流程控制、递归、搜索等“硬”推理模式，却又被语法噪声包裹。

CodeI/O 的核心想法：利用现成代码的执行结果当“真值函数”，把推理训练拆成输入& 输出预测，既保持可读的自然语言，又引入可执行的硬约束。

数据与任务构造流程: 

- 函数清洗收集 45 万个可执行 Python 函数，统一签名。 
- 采样 I/O独立的输入生成器为每个函数随机采样多组 I，执行得到 O。 
- 构造 Prompt把「函数源码 + 自然语言 Query + 已知 I 或 O」拼成提示，问“O或I是多少”。 
- 生成 CoT由 DeepSeek‑V2.5 直接产出自然语言推理链 + 预测。 
- 自动验证 & 修订执行函数核对预测；若出错，将执行反馈写回提示，促使同一模型自我改写。  

一个CodeI/O具体例子：  

假设已有验证函数： 
def remove_dups(nums): 
    return list(dict.fromkeys(nums))  
已知输入: [3, 2, 3, 2] 
query：请一步步推理并给出输出吗？  

模型用自然语言 CoT 演绎，最终输出 JSON：{"output": [3,2]}。同理可做给定 O 反推 I。所有答案立刻执行函数比对真值。  

一些思考：  

CodeI/O 并非训练 LLM 去“写代码”，而是借助现有代码当可执行“答案检查器”，把模糊的自然语言链式思考转化为可验证的 I/O 预测任务。它为通用推理预训练给出了一条兼顾可读性、精确性与可扩展性的路径。  

局限性也非常大，现有的代码函数，决定了什么样的 I/O 能被打上“对 / 错”标签；若只存在 N 个函数，训练或评测就只能覆盖这 N 种功能语义。它仍无法评判超出这些函数语义范围的答案。    

一句话，AI的能力边界，当然不该是这些函数的边界。  

DeepSeek的所有论文我都喜欢，风格也一致，方法上非常硬核，卷到极致。缺点也统一，非常task specific，有偏科的倾向。  


Spotify:
https://open.spotify.com/episode/2BjFoLGoEzeB0m32zJtvIq?si=JsCyQajfS4OoCqjUW0IVTA

Paper:
https://arxiv.org/abs/2502.07316
