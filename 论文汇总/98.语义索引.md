看到很多developer在使用向量数据库。

向量数据库或许是好用的，但它本质是针对词或句子的embedding的比较，我们在学术工作中已经做过评估，效果比传统的tfidf稍微好一点，但是tfidf可以非常轻量级的本地实现，所以有tradeoff。

如果要引入语义索引，建议用专门的information retrival system (IRS)


马东锡 NLP
@dongxi_nlp
·
Mar 21, 2023
如果有条件，自己部署一个neural-based IRS到云端，可以稳定高效的帮你完成query-document级别的搜索工作。

目前表现最强的的nerual irs是我前面推特提到的colbert。大家可以看一下。

https://github.com/stanford-futuredata/ColBERT

tephan
@Stephan_Talk
·
Mar 23, 2023
有个问题请教您一下，就是如果有两套方案（例如调用OpenAI embedding接口生成的向量数据库 和 自建IRS），如何比较科学的做效果的衡量对比？感觉自己人肉测的不一定准确又不自动化，abtest已经是产品上线后了太晚了。有没有科学准确的能够衡量两种语义检索方案效果的方法？谢谢！🙏


马东锡 NLP
@dongxi_nlp
·
Mar 23, 2023
需要一定的数据量，一般来说要评估一个推荐系统，一个query需要50个example [ref: https://nlp.stanford.edu/IR-book/information-retrieval-book.html 的evaluation章节]
非学术场景中没必要这么多，你可以标注一些推荐，看看rank结果，算一下average precision和mean average precision

我喜欢的论文分享： 

Composing retrieval and language models for knowledge-intensive NLP

非常接地气的一篇论文，通过引入information retrival system，简单直接的完成了in-context learning.



马东锡 NLP
@dongxi_nlp
·
Mar 21, 2023
简言之，用colbert完成对知识库的索引，并处理自然语言的query，配合其他llm完成knowledge-intensive NLP task。

广大gpt爱好者，可用此框架，打造出专家/个人知识库的chatgpt。
马东锡 NLP
@dongxi_nlp
·
Mar 21, 2023
论文：https://arxiv.org/abs/2212.14024



马东锡 NLP
@dongxi_nlp
·
Mar 21, 2023
论文code ： https://github.com/stanfordnlp/dsp


https://github.com/stanford-futuredata/ColBERT


马东锡 NLP
@dongxi_nlp
·
Mar 15, 2023
GPT系列的的优势在于zero shot的multi-task的能力，简言之，就是集合了问答翻译总结等等等任务于一个API让用户可劲造。
这种模式特别适合短平快的开发，用户仅凭各种prompt message就可以集合几个功能创造出一个搭积木产品？
但是我们还是要有一个问题，那就是然后呢？


马东锡 NLP
@dongxi_nlp
·
Mar 15, 2023
无论用户的产品逻辑搭的多么快，当产品成型之后，逻辑就固定下来，此时multitask就没有那么重要了。反而重要的是稳定性，可靠性。



马东锡 NLP
@dongxi_nlp
·
Mar 15, 2023
这就一下击中了gpt系列的软肋，zero shot。一般来说，zero shot是无法跟规模训练甚至微调后的模型的稳定性相比拟的，一般来说要落后50%的performance。
Zero shot，只能做到看上去很美。
zero shot

