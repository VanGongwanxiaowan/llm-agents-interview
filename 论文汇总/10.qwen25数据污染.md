「 Data Contamination，Qwen2.5 」

Qwen2.5 系列的 Data Contamination 问题被证实，模型在预训练阶段已经见过评测题目。

前几个月，数篇 LLM Reasoning + RL 的论文发现，用极弱或随机奖励即可显著提升 Qwen 系列数学推理能力。

这引发出 Qwen 模型在 pretraining 阶段已经见过评测题目的疑问。

今天分享的论文:
[ Reasoning or Memorization? Unreliable Results of Reinforcement Learning Due to Data Contamination ]

为了量化数据泄露程度，作者设计了 Partial-Prompt EM 和 Answer-Match Accuracy。

- Partial-Prompt EM：截取题目前半部分文本，让模型补全；若补全与原题后半部分 ROUGE-L=1，记为命中。

- Answer-Match Accuracy：仍用截断不完整题面，却只检查生成是否包含正确答案。

作者发现，在MATH-500 等benchmark，部分题仅给 40 %的题干，Qwen 仍能逐字补全原题并算出答案，泄漏迹象明显。

有很多工作都是基于Qwen2.5 模型，无论这些工作多么优秀，结果和发现的reliability都被打上了问号，感到可惜。


https://arxiv.org/abs/2507.10532

Kimi K2 的一大亮点，是将文本任务里基于 token 的处理思路，成功迁移到 Agentic 场景中的 tool-call 级别：在 Agentic 任务中，tool call 就相当于“行动 token”。

什么意思呢？解释如下：

在文本任务中:
CoT 是一串 token

而在Agentic 场景中：
CoT 是一段 tool-call 序列，即planning

在文本任务中：
用BLEU 或ROUGE等衡量生成文本与黄金答案在 token或字符层面的相似度，如具体的machine translation, summarization 等任务。

在Agentic 场景中
Process Accuracy，用来衡量实际 tool-call 序列与理想动作轨迹的匹配度，颗粒度（这个词挺合适的😅）是tool call 级别的。

如此一来，Kimi K2 在Agentic 场景中实现了与传统 NLP 的联系，使模型的规划与执行得以像文本生成那样可度量和优化。

读了 Kimi K2 的 blog，Agentic Capabilities 令人印象深刻。

如blog中所说，Kimi K2 借鉴了ACEBench，在evaluation上，不仅衡量端到端 End Accuracy，针对每一步tool call也给出 Process Accuracy，这种对process的重视，能显著提升 LLM 的 Planning 能力。

所以，JavaScript Minecraft 和 RustFlask的例子，醒目的planner把一步步的计划放在最前面。

题外话，这种planner + excution的方式，几乎就是 ReWOO。我日常用的agent workflow，也几乎只用两种，ReAct + ReWOO。Kimi K2其实很像ReWOO+ReACT（当然他把这种policy训练到了模型权重）：
思考阶段生成成蓝图（ReWOO的planner）；在执行阶段，需要ReACT模式调用观察修正plan。

ReWOO的缺点是无法修正plan，但适合简单直接流程化的任务。ReWOO 是把plan of tool calling作为CoT输出，本质上解耦思考和执行。
ReAcT是边思考边执行边观察，思考和执行是交错的进行的。
