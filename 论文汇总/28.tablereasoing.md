「RLVR, Table Reasoning」

Table-R1: Inference-Time Scaling for Table Reasoning

Inference-Time Scaling 并非数学或coding的专属，在高结构化数据推理中，也可把“想得更久”转化为性能。

跳出math和coding的盒子，作者首次将 ITS 系统性地迁移到结构化数据（如 tabular data）推理的研究。

在使用post training recipe后，7 B 基座就能在多类表格推理任务上并肩 GPT-4.1 与 DeepSeek-R1。

在方法上，两条 post-training 路线：
- Table-R1-SFT
用 DeepSeek-R1 生成的长 CoT 轨迹，构建大规模监督数据集做指令微调

- Table-R1-Zero
设计三类适合RLVR的奖励：
-- 短答 Table QA -> 精确匹配 (EM)；
-- 表格事实核验 -> 布尔正确性；
-- 自由问答 -> ROUGE-L / BLEU 与答案一致度；

值得一提的是，在Qwen之外，作者同时尝试了Llama-3-8B， 点赞！

在实验中，使用多种模型，验证其方法的可移植性，Qwen
和Llama 基座在post training后，均表现出良好性能。

思考：
在实际 场景中，Table Reasoning 具有特别的数据安全和隐私的考量，往往不希望直接暴漏数据给大模型厂商。
Table-R1 的出现解决了这个问题, 为数据库/BI /投研垂直Agent提供思路。
表格任务天然有“程序可判”的结果，这让 RLVR 变得干净、高效，RLVR的方法可以继续探索。

与本论文无关。spurious reward之后，Qwen陷入争议。
跳出math和coding，Qwen依然表现出色，希望看到更多的多领域工作为 Qwen 正名。


https://arxiv.org/abs/2505.23621
