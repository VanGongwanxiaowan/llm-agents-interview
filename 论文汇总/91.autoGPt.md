
马东锡 NLP
@dongxi_nlp
·
Apr 16, 2023
关于AutoGPT的疑惑, 它到底有没有CoT?

昨天发了关于AutoGPT的thread，断言它的prompt没有CoT是它的致命缺陷。

今日重新思考了这个问题，并在两位读者的指正和讨论下，重新看了AutoGPT的代码，整理了一下思考，感觉昨天的结论下的有些不严谨。

那么AutoGPT到底有没有CoT?

<img width="1200" height="670" alt="image" src="https://github.com/user-attachments/assets/abe2f40c-3222-46a1-a7ff-20a9befd4809" />

马东锡 NLP
@dongxi_nlp
·
Apr 16, 2023
2/n 根据AutoGPT的代码，粗略地画了它构建prompt message的流程图。

prompting llm是AutoGPT的关键，所以整个过程中它到底是怎样构建prompt message非常重要。

总的来说，四个部分构成了它的prompt message，分别为
user
postfix
memory
template

马东锡 NLP
@dongxi_nlp
·
Apr 16, 2023
3/n 这四个部分中，只有prompt template是不变的。

在上个thread中有介绍，AutoGPT的prompt template主要是要让llm生成带有thought和command键值的json，这样以来，command可以被容易地解析出来让用户执行。


马东锡 NLP
@dongxi_nlp
·
Apr 16, 2023
4/n 其余三个组成部分（user，postfix，memory）在不同的阶段都有变化，具体来说可以分为两个阶段：

生成第一个command的阶段（noted 阶段一）
第一个command执行完之后的阶段 （noted 阶段二）


马东锡 NLP
@dongxi_nlp
·
Apr 16, 2023
5/n 阶段一

user input：ai name/role/goals
memory为空
但值得注意的是，AutoGPT为prompt postfix设置了一个默认值：
“Determine which next command to use, and respond using the format specified above:”



马东锡 NLP
@dongxi_nlp
·
Apr 16, 2023
6/n  所以第一阶段的prompt message为

"ai name/role/goals + memory[空] + template + postfix"

prompting LLM， “同时” 生成了thought 和 command的json

马东锡 NLP
@dongxi_nlp
·
Apr 16, 2023
7/n 阶段二

假设用户选择执行生成的command，输入y
postfix变为了：GENERATE NEXT COMMAND JSON

这个postfix连同执行command产生的结果，以及上一步生成的json一起更新了memory

memory = [json from previous step + result from previous command + postfix]


马东锡 NLP
@dongxi_nlp
·
Apr 16, 2023
8/n 所以第二阶段的prompt message为

"ai name/role/goals, + template + memory [json from previous step + result from previous command + postfix]  + postfix"

prompting LLM，再次 “同时” 生成 thought 和 command

接下来，是循环阶段二的动作，执行command，更新memory...



马东锡 NLP
@dongxi_nlp
·
Apr 16, 2023
9/ AutoGPT的prompt 建立过程中有几个疑惑点

1：“Determine which next command to use, and respond using the format specified above:”  以及 GENERATE NEXT COMMAND JSON 能不能起到 ‘let‘s think step by step’的神奇作用？

2: AutoGPT到底有没有CoT？

马东锡 NLP
@dongxi_nlp
·
Apr 16, 2023
10/n step by step的核心步骤是把step by step生成的CoT反贴生成新的prompt来生成action，总而言之，llm被prompt了两次

而AutoGPT只prompt了一次，而且‘同时’ 生成了thought和action

这似乎跟step by step的步骤不同。


马东锡 NLP
@dongxi_nlp
·
Apr 16, 2023
11/n 在阶段一，AutoGPT的memory为空，完全依赖一个静态的prompt message，没有显性的CoT

同时，CoT，step by step和ReAct的核心都是要具有针对当下action的thought。

但在阶段二，AutoGPT依赖的memory记录的是previous step的command result和thought， 似乎与当下的action联系没有那么强烈？

2/12

抛开炫酷的demo，AutoGPT最核心的代码，是prompt message的构成方式，即：

把用户输入的ai name/role/goals直接合并在它默认的prompt message中。

它的本质，还是在prompting。

construct full prompt message：
https://github.com/Torantulino/Auto-GPT/blob/master/scripts/ai_config.py

default prompt message：
https://github.com/Torantulino/Auto-GPT/blob/master/scripts/prompt.py


<img width="889" height="176" alt="image" src="https://github.com/user-attachments/assets/de189036-63b1-44d8-8fd0-349dffbfbcdb" />



马东锡 NLP
@dongxi_nlp
·
Apr 14, 2023
3/12 仔细看一下prompt message

亮点是，通过constraints和performance evaluations要求llm使用缓存，并强行要求输出json格式，键值包含了所谓的reasoning和planning，以及选中的command api。

这其中的reasoning引起了我的注意，它真的有在reasoning么？

<img width="719" height="341" alt="image" src="https://github.com/user-attachments/assets/fafc12af-1bd8-4669-aab2-73c8bcfa38e7" />


马东锡 NLP
@dongxi_nlp
·
Apr 14, 2023
4/12 阅读我之前的CoT和ReAct的读者已经知道，大语言模型的推理（reasoning）是一种涌现行为，具体指:
只有在引入CoT之后，超过1000亿参数的大模型才能解锁reasoning能力。


马东锡 NLP
@dongxi_nlp
·
Apr 14, 2023
5/12 可以确定的是，AutoGPT的prompting 方式没有显性的引入CoT，所以没有解锁reasoning。

它只能严重依赖缓存做desicion making，一遍遍的重复action，有勇无谋，可以说它并没有真正在做reasoning。

在以token计费的背景下，这种局限性被放大，徒有炫酷，让一般开发者望而却步。

马东锡 NLP
@dongxi_nlp
·
Apr 14, 2023
6/12 大语言模型学习使用工具和调用api的发展历程，大概以CoT和ReAct为界。

CoT和ReAct之前，大语言模型主要靠昂贵的human feedback来做reinfocement learning来学会call api。
例如 WebGPT: 让LLM学会调用bing search api
https://arxiv.org/abs/2112.09332

<img width="1200" height="458" alt="image" src="https://github.com/user-attachments/assets/0a307c7c-3d70-47db-8980-e3d379ade1d2" />



马东锡 NLP
@dongxi_nlp
·
Apr 14, 2023
6/12 大语言模型学习使用工具和调用api的发展历程，大概以CoT和ReAct为界。

CoT和ReAct之前，大语言模型主要靠昂贵的human feedback来做reinfocement learning来学会call api。
例如 WebGPT: 让LLM学会调用bing search api
https://arxiv.org/abs/2112.09332
马东锡 NLP
@dongxi_nlp
·
Apr 14, 2023
7/12 ReAct 将CoT动态地引入到LLM学习call api的过程中，用CoT大道至简的思想，让LLM在完成api calling这个decision making前，具有推理过程，轻量级地解决了模型学习api的问题。

有兴趣的读者可以去读我的ReAct读书笔记。


马东锡 NLP
@dongxi_nlp
·
Apr 14, 2023
8/12 ReAct的进阶MM-REACT

MM-REACT是ReAct的进阶，通过运用ReAct的思想，完成多模态复杂任务。

MM-REACT把ChatGPT作为智能coordinator，协调视觉专家模型完成任务，特别的是，MM-REACT显性地用thought/action/observation这种ReAct模式进行prompting。

https://arxiv.org/abs/2303.11381

<img width="761" height="659" alt="image" src="https://github.com/user-attachments/assets/d4fb6586-6b8a-41ad-9857-64eb4f67cb35" />


马东锡 NLP
@dongxi_nlp
·
Apr 14, 2023
9/12 当我们回顾LLM的使用工具的发展，随着模型越来越大，带来的变化是：
1: 做fintune或用human feedback reinforcement learning越来越昂贵。
2: 大模型的涌现能力，让zero-shot/few-shot成为潮流。



马东锡 NLP
@dongxi_nlp
·
Apr 14, 2023
10/12 在这一潮流中

CoT扮演了重要的角色，它解锁了模型涌现推理能力，帮助llm完成了对自身知识的潜能挖掘；

ReAct将CoT推进到了大模型运用外部工具的层面，弥补了大模型依赖预训练知识的局限性；

MM-ReAct进一步将拓展了语言模型的应用边界，超越了语言文字的范畴。



马东锡 NLP
@dongxi_nlp
·
Apr 14, 2023
11/12 如果此时在此回看AutoGPT, 发现它在middle of no where，它是prompting的本质，既没有reinforcement learning的加持，又没有CoT，它像一个实习生，动力十足，但思维跟不上。

但CoT本质也是prompting，它是如此轻成本，如果AutoGPT引入CoT, 会更可怕。





