「Nvidia, Reasoning, Agent」

Nemotron-Research-Tool-N1: Exploring Tool-Using  Language Models with Reinforced Reasoning

Nemotron-Tool-N1 是 RLVR 思想在 tool calling 维度的深化版本，让 7 B / 14 B 模型在工具类基准全面领先 GPT-4o。精彩的工作！

无需为每一步推理标注轨迹，也不用先做大规模 SFT。只凭轻量级 Reinforcement Learning with Verifiable Rewards（RLVR），模型即可自行内化推理策略。

在 DeepSeek-R1 首次把 “verifiable reward + GRPO” 带入公众视野之后，Tool-N1 作者明确称自己采用 “R1-style RL”，并在工具调用领域验证了同一路线。

目标任务：
-  JSON 工具调用
<think>…</think><tool_call>[{…}]</tool_call>
奖励函数：
- JSON 可解析；
- 工具名在候选列表；
- 参数语义等价 → reward = 1，否则 0。

思考：
只要能写出确定性的 is_valid(output) 判定器，RLVR 思想几乎可以无缝迁移到任何需要 LLM 生成“可执行动作”的场景， 从数学、编程到 API 编排。
再进一步，“可执行动作”的<tool_call> token，替换为<vision/video>，其他Visual-RLVR的训练原理，也清晰明了。

<img width="816" height="1200" alt="image" src="https://github.com/user-attachments/assets/f2900632-7cf3-4123-9c54-22b20064ba70" />

arxiv.org/abs/2505.00024
