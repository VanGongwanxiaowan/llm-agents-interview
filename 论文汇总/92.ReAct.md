1/ ReAct: 大语言模型推理，决断和行动的关键

最近大语言模型突破了文字处理任务的限制，向智能coordinator的角色转化。

一个疑问随之而来，“LLM到底如何决断并采取行动来调用不同的api的？”

本条thread读书笔记，通过解读论文ReAct，同时介绍langchain的一个具体例子来试图回答这个问题。


马东锡 NLP
@dongxi_nlp
·
Apr 8, 2023
2/ paper: ReAct: Synergizing Reasoning and Acting in Language Models.

关键词 [推理]，[行动]

LLM有没有主动推理能力？目前没有确切答案。

但是可以明确的是，随着Chain-of-Thought(CoT)的引入，LLM的推理能力可被解锁。

CoT是ReAct的前提，我之前有thread专门介绍CoT，感兴趣的读者可以去阅

马东锡 NLP
@dongxi_nlp
·
Apr 8, 2023
3/ CoT, 简言之就是把人的思维过程嵌入到prompt，指导LLM完成思考做出预测。

CoT的问题在于，它是静态的。

而我们人类，在行动之前，总是要根据环境和条件的变化不断的产生新的，动态的CoT来指导不同的行动。

同样的，LLM在充当智能coordinator的过程中，也需要根据不同的情况，call不同的api。

马东锡 NLP
@dongxi_nlp
·
Apr 8, 2023
4/ 静态CoT在multi-hop的问题中尤其挣扎。

例图中问题，[device] ... [program] ? 是一个多跳问题，我们需要通过外部知识首先定位到program，然后才能回答哪个device可以control这个program

这种情况下，LLM产生的静态CoT出现了知识和逻辑的错误（apple tv不是progrm），导致最终预测失败

<img width="651" height="536" alt="image" src="https://github.com/user-attachments/assets/c97a24e7-210e-4193-accb-80412d3b654f" />

马东锡 NLP
@dongxi_nlp
·
Apr 8, 2023
5/ 为了解决此问题

ReAcT的作者首先设计了简单的wikipedia api(search, lookup, finish)来通过的外部知识协助LLM

其次，作者在call api之前和之后，显性的放入Thought和observation，用来指导和调整api的调用策略

这本质上还是CoT, 不过因为oberve了外部环境，CoT随之变化，打破了静态性

<img width="607" height="507" alt="image" src="https://github.com/user-attachments/assets/25bd46c0-b54d-4213-9e41-c0c3c4ef6e37" />


马东锡 NLP
@dongxi_nlp
·
Apr 8, 2023
6/ 总结作者使用的prompt

Thought, Act, Obs
Thought, Act, Obs
Thought, Act, Obs

简单的Re(reasoning)Act(Act) prompting, 并通过few-shot的方式，让LLM学会call api，并以[Finish]作为任务完成的标志。


马东锡 NLP
@dongxi_nlp
·
Apr 8, 2023
7/ 如果拓展开来，把多跳问题换成其他，把wikipedia的api换成任意别的api，ReAct这种work flow其实可以移植到任何场景。

例如接下来的例子：

利用langchain来调用spotify的api来根据用户的自然语言指令，创建歌单。

马东锡 NLP
@dongxi_nlp
·
Apr 8, 2023
8/ 当我们仔细看它的log输出，会发现熟悉的：

Thought, Act, Obs
Thought, Act, Obs
Thought, Act, Obs

如果你看完了我的这条thread，就会知道langchain一定是借鉴了ReAct的方法。
我们去它的github看一下源代码，果然如此，用了同样的ReAct的fewshot方式做了封装。

<img width="1200" height="684" alt="image" src="https://github.com/user-attachments/assets/d71dd977-aa85-495a-8274-5908e91e93ec" />


马东锡 NLP
@dongxi_nlp
·
Apr 8, 2023
我个人必读论文list有：
trasnformer：attention is all you need, 
encoder blocks：BERT
encoder-decoder blocks： BART
decoder-blocks: GPT-1, 2, 3
prompt-based learning
instruct tuning
cot, react 

YouTube的Mu Li老师讲的非常好
我自己也会逐步把这些论文写成thread






