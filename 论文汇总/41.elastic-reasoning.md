「LLM, Efficient Reasoning」论文

Scalable Chain of Thoughts via Elastic Reasoning

Elastic Reasoning，让模型思考过程如同调节音量般可控，在 token budget 限制内，完成推理。

一篇出色的paper！面对思考模型 test-time scaling 中 CoT 长度不可控的问题，作者提出了非常 smart 的解决方案：

- 通过 “协议 token” <think> … </think> 把 Chain-of-Thought 拆分成 thinking 与 solution 两段,  即：
模型输出 = (<think> thinking </think>, solution)。

- 独立预算 ：为thinking和solution分别设置 token 上限 t 和s。

- 采用预算受限回滚训练 (budget-constrained rollout)： 在 GRPO 强化学习流程里，随机截断思考段再继续训练，迫使模型学会“若思考被打断，仍能拼出高质量解答”。

特别地，elastic reasoning 的 budget 模式如下：

- 模型从 <think> 开始生成推理过程即thinking。
- 若在预算 t 内主动输出 </think>，立即转入solution；否则当计数达到 t 时强行插入 </think>，结束思考。
- 继续生成，直到用完 s 或模型提前结束。

值得注意的是： 
Elastic Reasoning 里的 budget 由调用者（API、前端服务）显式设定，模型本身并不去学会分配或动态决定预算。模型真正学到：

“无论留给我多少思考 token，只要到了上限就立刻收尾，并在接下来的解答 token 里给出尽量正确的答案。”

作者发现，训练后的模型即使在无buget限制模式，也倾向于更短链条，事实上达到了 efficient reasoning 的效果。

一些思考：

作者将 “协议 token” 从具体任务延展到计算资源分配， exciting！与其他具体 function-calling 类型的协议 token (Search, code intepreter，async) 组合，可能会带来更多的惊喜。

Elastic reasoning 可以做到 budget 可控，让用户可以主动地控制和分配 token 资源。

目前Elastic reasoning 局限性在于，budget是静态被动输入的，如果buget可以根据问题难度和场景动态分配，更令人期待！

Links:

Spotify: https://creators.spotify.com/pod/show/ke-devin-yow/episodes/Elastic-Reasoning-e32kqgo

Paper:  https://arxiv.org/abs/2505.05315
