「Concurrent Reasoning, Agent 」

Group Think: Multiple Concurrent Reasoning Agents Collaborating at Token Level Granularity

打破 “位置和时间” 的强约束，让 LLM 获得 “过去，现在，和将（jiǎng）来” 的跨思考能力。

“token generation order is decoupled from positional indices, yet each new token can attend to all previously generated tokens”

Group Think 通过极小的解码改动，让单个大模型在同一序列中扮演多名“思考者”，实现 token 级并行推理。

太精彩！

在post training眼花缭乱的当下，通过零微调，作者仅凭为每位thinker预留错开的位置编号，形成毫秒级协作。

具体在方法上：

- 预分 slot
思考者 1 占 110-169，思考者 2 占 170-229。
slot 间留空位，放各自的 “我是 Thinker k” 提示。

- 逐步交错（Step-wise interleaving）
在生成步 t，模型把每位思考者的下一个 token 写到自己的下一空槽。

生成序列：
thinker-1-prompt (101-110)
thinker-1--tok (111) 
thinker-2-prompt (161-170)
thinker-2-tok(171)
thinker-1-tok(112)
…

-共享 KV 缓存（Shared KV cache）
所有 token 存于同一 KV buffer，因此任何新 token 都能注意到 “时间上更早” 的所有 token。

如此一来，思考者可以在写到一半时发现 “同伴已给出关键中间结论”，立即调整方向，避免重复劳动，传统回合式方案做不到。

在零微调的前提下，Group Think 的推理延迟大约按思考者数量 N 成比例缩短，同时在多项任务上取得比单链式思CoT 和独立采样更高的覆盖率与正确率。

https://arxiv.org/abs/2505.11107
