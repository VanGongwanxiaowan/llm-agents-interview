好的，我们来详细解释一下RAG的检索召回率以及Ragas中各项核心指标的公式。

### 1. RAG检索召回率

在RAG系统中，**检索召回率** 是一个用于评估**检索器**性能的关键指标。它衡量的是：在所有**真正相关**的文档 chunks 中，检索器成功找回了多少。

其计算公式为：

$$\text{检索召回率} = \frac{|\{\text{相关文档}\} \cap \{\text{检索到的文档}\}|}{|\{\text{相关文档}\}|}$$

**具体解释：**
*   **分母 (|\{\text{相关文档}\}|):** 针对当前问题（Query），数据集中**所有被认为相关的文档片段**的总数。这通常由人工标注确定，是“标准答案”集合。
*   **分子 (|\{\text{相关文档} \cap \{\text{检索到的文档}\}|):** 检索器**实际返回的文档片段**中，与标注的相关文档片段**重合的数量**。

**示例：**
假设一个问题，数据集中有5个文档片段（Doc A, B, C, D, E）被标注为相关（标准答案）。
*   你的检索器返回了3个文档：Doc A, Doc C, Doc F。
*   其中，Doc A 和 Doc C 是相关的，Doc F 不相关。

那么，检索召回率 = 2 (A和C) / 5 (A, B, C, D, E) = 0.4 (或 40%)

**重要性：** 召回率越高，说明检索器“漏掉”的相关信息越少，为后续的生成阶段提供充足、准确证据的可能性就越大。它是影响最终答案质量的基础。

---

### 2. Ragas 各项指标的公式

Ragas 是一个专门用于评估RAG系统质量的框架。它不直接使用“检索召回率”这个需要人工标注所有相关文档的指标，而是通过一系列其他可自动或半自动计算的指标来综合评估。以下是其核心指标的公式和思想：

Ragas的指标主要分为两大类：**面向答案的指标** 和 **面向检索的指标**。

#### 面向答案的指标

这些指标评估最终生成的答案（Response）的质量。

**1. 答案正确性**
这通常不是一个单一的公式，而是由**忠实度**和**答案相关性**共同构成。

*   **忠实度 (Faithfulness)**
    *   **概念：** 衡量答案中的陈述是否都能从给定的上下文（检索到的文档）中推导出来，是否存在无法验证的“幻觉”。
    *   **公式/方法：** 通常使用LLM进行评估。
        1.  从生成的答案中提取所有独立的“声明”或“事实” (Claims)。
        2.  让LLM判断每个“声明”是否能从给定的上下文中推断出来（True/False）。
        3.  忠实度 = $\frac{\text{Number of Faithful Claims}}{\text{Total Number of Claims}}$

*   **答案相关性 (Answer Relevancy)**
    *   **概念：** 衡量生成的答案对原始问题的相关程度。一个高度相关的答案会直接解决问题，不会包含多余或不相关的信息。
    *   **公式/方法：** 使用LLM进行评估。
        1.  让LLM根据生成的答案**反向生成可能的问题** (Generated Questions)。
        2.  计算原始问题 (Original Question) 和这些生成问题 (Generated Questions) 之间的相似度（通常使用嵌入模型计算余弦相似度）。
        3.  答案相关性 = $\frac{1}{N} \sum_{i=1}^{N} \text{sim}(Q_{\text{original}}, Q_{\text{generated}_i})$ （通常N=3）

**2. 答案相似度 (Answer Similarity)**
*   **概念：** 在有标准答案（Ground Truth）的情况下，衡量模型生成的答案与标准答案的语义相似度。
*   **公式：** 使用句子嵌入模型（如BERT）获取生成答案和标准答案的向量表示，然后计算它们的**余弦相似度**。
    $$\text{Answer Similarity} = \frac{\mathbf{A}_{\text{gen}} \cdot \mathbf{A}_{\text{gt}}}{\|\mathbf{A}_{\text{gen}}\| \|\mathbf{A}_{\text{gt}}\|}$$

#### 面向检索的指标

这些指标评估检索器提供的上下文（Context）的质量。

**1. 上下文精度 (Context Precision)**
*   **概念：** 衡量在检索到的所有文档中，相关文档的位置是否靠前。它不仅关心有多少相关的被召回，还关心它们的排序质量。
*   **公式/方法：**
    1.  对于检索返回的每个文档片段（按顺序），检查它是否相关（需要人工标注或LLM判断单个片段的相关性）。
    2.  在每个排序位置，计算截止到该位置的精度值。
    3.  对所有位置的精度值取平均。

    $$\text{Context Precision} = \frac{1}{N} \sum_{k=1}^{N} \left( \frac{\text{Number of relevant items up to } k}{k} \times \text{rel}(k) \right)$$
    其中 `rel(k)` 是指示函数，如果第k个文档相关则为1，否则为0。N是检索到的文档总数。

**2. 上下文召回率 (Context Recall)**
*   **概念：** 这是最接近传统“检索召回率”的Ragas指标。但它巧妙地利用**生成的答案**作为代理，避免了人工标注**所有**相关文档。
*   **公式/方法：**
    1.  将生成答案中声称的所有“事实”或“声明” (Claims) 视为“需要被支持的真理”。
    2.  检查检索到的上下文中有多少能够支持这些声明。
    3.  上下文召回率 = $\frac{\text{Number of claims supported by the context}}{\text{Total number of claims in the answer}}$

    这是一种实用的、以答案驱动的召回率近似方法。如果答案中的所有事实都能在上下文中找到依据，那么上下文召回率就是100%，说明检索器提供了足够的信息。

**3. 上下文实体召回率 (Context Entity Recall) - 可选**
*   **概念：** 衡量检索到的上下文是否包含了问题中提到的关键实体（如人名、地点、组织等）。
*   **公式：**
    1.  从问题中提取所有命名实体 (Entities in Question)。
    2.  检查这些实体有多少出现在检索到的上下文中。
    3.  上下文实体召回率 = $\frac{\text{Number of entities found in the context}}{\text{Total number of entities in the question}}$

### 总结

| 指标 | 类型 | 核心思想 | 公式概要 |
| :--- | :--- | :--- | :--- |
| **检索召回率** | 检索器指标 | 所有相关文档中，被找回了多少 | 相关且检索到的 / 所有相关的 |
| **忠实度** | 答案质量 | 答案是否基于上下文，无幻觉 | 可验证的声明数 / 总声明数 |
| **答案相关性** | 答案质量 | 答案是否直接针对问题 | 原始问题与生成问题的相似度 |
| **答案相似度** | 答案质量 | 生成答案与标准答案的语义相似度 | 向量余弦相似度 |
| **上下文精度** | 检索质量 | 相关文档是否排在前面 | 加权平均精度 |
| **上下文召回率** | 检索质量 | 检索到的上下文能支持多少答案中的声明 | 被支持的声明数 / 总声明数 |
| **上下文实体召回率** | 检索质量 | 上下文是否包含问题中的关键实体 | 上下文中的实体数 / 问题中的实体数 |

Ragas通过组合这些指标，提供了一个全面评估RAG系统**检索器**和**生成器**质量的框架，而无需完全依赖昂贵的人工标注。

# 评估指标
检索器评估指标
## 准确率：
context precision

t he signal to moise ratio of retrieved context

评估查询结果准不准确
## 召回率
系统检索出相关的文档，所有实际相关的文档

context recall

can it retrieve all the relevant information required to answer the question

评估查询结果全不全

## 生成器评估指标

## 忠实度

指的是生成结果是基于检索的结果，事实准确的，评估生成内容是否是谎言

faithfulness

how factually acurate is the generated answer
## 相关性
answer relevancy

how relevant is the generated answer to the question
